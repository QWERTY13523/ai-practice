import os
import sys
import torch
import torchaudio
import io
import uuid
import uvicorn
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import Response

# === 1. é…ç½®è·¯å¾„ ===
# è¯·ä»”ç»†æ£€æŸ¥ä½ çš„ CosyVoice é¡¹ç›®è·¯å¾„æ˜¯å¦æ­£ç¡®
COSY_ROOT = "/home/nyw/AI-practice/CosyVoice"
sys.path.append(COSY_ROOT)
sys.path.append(os.path.join(COSY_ROOT, "third_party", "Matcha-TTS"))

# ã€é‡è¦ã€‘å¿…é¡»æŒ‡å‘ 300M åŸºç¡€æ¨¡å‹ï¼ˆCloneç‰ˆï¼‰ï¼Œä¸èƒ½æ˜¯ SFT ç‰ˆ
MODEL_DIR = os.path.join(COSY_ROOT, "pretrained_models/CosyVoice-300M")

try:
    from cosyvoice.cli.cosyvoice import CosyVoice
    from cosyvoice.utils.file_utils import load_wav
except ImportError:
    print("âŒ [8001] å¯¼å…¥ CosyVoice å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„é…ç½®ã€‚")
    sys.exit(1)

app = FastAPI()

# === 2. åŠ è½½æ¨¡å‹ ===
print(f"ğŸš€ [8001-GPU] æ­£åœ¨åŠ è½½å…‹éš†æ¨¡å‹: {MODEL_DIR} ...")
if not os.path.exists(MODEL_DIR):
    print(f"âŒ [8001] è‡´å‘½é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹ç›®å½• {MODEL_DIR}")
    print("ğŸ‘‰ è¯·ä¸‹è½½ CosyVoice-300M æ¨¡å‹ï¼ˆé SFTï¼‰æ‰èƒ½ä½¿ç”¨æ–‡ä»¶å…‹éš†åŠŸèƒ½ã€‚")
    sys.exit(1)

try:
    model = CosyVoice(MODEL_DIR)
    print("âœ… [8001] CosyVoice-300M åŠ è½½æˆåŠŸï¼(æ”¯æŒæ–‡ä»¶ä¸Šä¼ )")
except Exception as e:
    print(f"âŒ [8001] æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

# === 3. å®šä¹‰æ¥å£ (Form + File) ===
@app.post("/generate")
async def generate(
    text: str = Form(...),              # æ¥æ”¶æ–‡æœ¬ (Formè¡¨å•)
    prompt_wav: UploadFile = File(...)  # æ¥æ”¶æ–‡ä»¶ (Fileè¡¨å•)
):
    """
    æ¥æ”¶: text + prompt_wav
    æ¨¡å¼: è·¨è¯­è¨€/é›¶æ ·æœ¬å…‹éš† (æ— éœ€ prompt_text)
    """
    temp_file = f"temp_narrator_{uuid.uuid4()}.wav"
    try:
        # 1. ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘
        content = await prompt_wav.read()
        with open(temp_file, "wb") as f:
            f.write(content)

        # 2. æ£€æŸ¥éŸ³é¢‘æœ‰æ•ˆæ€§
        speech_16k = load_wav(temp_file, 16000)
        if speech_16k.shape[1] < 16000 * 1:
             raise HTTPException(status_code=400, detail="å‚è€ƒéŸ³é¢‘å¤ªçŸ­ (<1s)")

        # 3. æ¨ç† (ä½¿ç”¨ cross_lingual æ¥å£)
        print(f"ğŸ¤ [8001]æ­£åœ¨å…‹éš†æ—ç™½: {text[:10]}...")
        output = model.inference_cross_lingual(text, speech_16k, stream=False)

        # 4. æ‹¼æ¥å¹¶è¿”å›
        chunks = [item['tts_speech'] for item in output]
        if not chunks:
            raise HTTPException(status_code=500, detail="ç”Ÿæˆç»“æœä¸ºç©º")

        final_audio = torch.cat(chunks, dim=1)
        
        buffer = io.BytesIO()
        torchaudio.save(buffer, final_audio.cpu(), model.sample_rate, format="wav")
        buffer.seek(0)
        
        return Response(content=buffer.read(), media_type="audio/wav")

    except Exception as e:
        print(f"âŒ [8001] æ¨ç†å‡ºé”™: {e}")
        # è¿”å› 500 è€Œä¸æ˜¯é»˜è®¤çš„ validation errorï¼Œé˜²æ­¢ unicode å´©æºƒ
        return Response(content=f"Server Error: {str(e)}", status_code=500)
    finally:
        if os.path.exists(temp_file):
            os.remove(temp_file)

if __name__ == "__main__":
    # å¼ºåˆ¶è¿è¡Œåœ¨ 8001
    uvicorn.run(app, host="0.0.0.0", port=8001)