import os
import json
import uuid
import requests
import re
import shutil
import time
import glob
import random
import traceback
from fastapi import FastAPI, UploadFile, File, BackgroundTasks, Request, HTTPException
from fastapi.responses import FileResponse, HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydub import AudioSegment

from openai import OpenAI

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# ================= 1. é…ç½®è·¯å¾„ =================
UPLOAD_DIR = "uploads"
OUTPUT_DIR = "outputs"
TEMP_VOICE_DIR = "uploads/custom_voices"
VOICE_POOL_DIR = "/home/nyw/AI-practice/resource/input_audio"
BGM_DIR = "/home/nyw/AI-practice/resource/pre_train_wav/background" 

# ç¡®ä¿ç›®å½•å­˜åœ¨
for d in [UPLOAD_DIR, OUTPUT_DIR, TEMP_VOICE_DIR, VOICE_POOL_DIR, BGM_DIR]:
    os.makedirs(d, exist_ok=True)

# GPU æœåŠ¡åœ°å€
URL_COSY = "http://localhost:8005/generate" # ç¡®ä¿è¿™é‡Œç«¯å£æ˜¯ä½ CosyVoiceæœåŠ¡çš„ç«¯å£
URL_INDEX = "http://localhost:8002/generate"

TASKS = {}

# ================= 2. åˆå§‹åŒ–å¤§æ¨¡å‹ =================
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY") or "sk-cfc644272f8b4be2aa58f9b240636083"
client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# ================= 3. å·¥å…·å‡½æ•°ï¼šéŸ³é¢‘å¤„ç† =================

def match_target_amplitude(sound, target_dBFS=-20.0):
    """å°†éŸ³é¢‘å“åº¦ç»Ÿä¸€è°ƒæ•´åˆ° target_dBFS"""
    change_in_dBFS = target_dBFS - sound.dBFS
    return sound.apply_gain(change_in_dBFS)

def mix_speech_with_bgm(speech_seg, bgm_path):
    """
    å•å¥æ··åˆé€»è¾‘ï¼š
    1. è¯»å– BGM
    2. å¾ªç¯ BGM ç›´åˆ°è¦†ç›–äººå£°é•¿åº¦
    3. è°ƒæ•´ BGM éŸ³é‡ï¼ˆå‹ä½ï¼‰
    4. è£å‰ªå¹¶åšæ·¡å…¥æ·¡å‡º
    5. æ··åˆ
    """
    if not bgm_path or not os.path.exists(bgm_path):
        return speech_seg 
    
    try:
        bgm = AudioSegment.from_file(bgm_path)
        
        # 1. ç»Ÿä¸€åŸºå‡†éŸ³é‡
        bgm = match_target_amplitude(bgm, -20.0)
        
        # 2. å‹ä½èƒŒæ™¯éŸ³ (æ¯”äººå£°ä½ 12dB)
        bgm = bgm - 12 
        
        # 3. å¾ªç¯å¡«å……
        target_len = len(speech_seg) + 500
        if len(bgm) < target_len:
            loop_count = (target_len // len(bgm)) + 1
            bgm = bgm * loop_count
            
        # 4. è£å‰ª
        bgm = bgm[:target_len]
        
        # 5. æ·¡å…¥æ·¡å‡º
        bgm = bgm.fade_in(500).fade_out(500)
        
        # 6. å åŠ 
        mixed = speech_seg.overlay(bgm, position=0)
        return mixed

    except Exception as e:
        print(f"âš ï¸ BGMèåˆå¤±è´¥ [{os.path.basename(bgm_path)}]: {e}")
        return speech_seg

# ================= 4. LLM åˆ†æé€»è¾‘ =================

def get_all_bgm_filenames():
    """è·å– BGM ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶å"""
    files = []
    if os.path.exists(BGM_DIR):
        for f in os.listdir(BGM_DIR):
            if f.lower().endswith(('.mp3', '.wav', '.flac')):
                files.append(f)
    return files

def parse_json_output(text_output):
    print(f"----- LLM åŸå§‹è¿”å› (å‰100å­—) -----\n{text_output[:100]}...\n-------------------------------")
    clean_text = re.sub(r'```json\s*', '', text_output)
    clean_text = re.sub(r'```', '', clean_text).strip()
    try:
        data = json.loads(clean_text)
        results = []
        for item in data:
            role = item.get("role", item.get("è§’è‰²", "æ—ç™½")).strip()
            emotion = item.get("emotion", item.get("æƒ…ç»ª", "å¹³æ·¡"))
            text = item.get("text", item.get("å°è¯", ""))
            bgm = item.get("bgm", "") 
            
            if "æ—" in role and "ç™½" in role: role = "æ—ç™½"
            if role.lower() == "narrator": role = "æ—ç™½"
            
            results.append({"è§’è‰²": role, "æƒ…ç»ª": emotion, "å°è¯": text, "bgm": bgm})
        return results
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        return []

def analyze_novel_roles_llm(text_content):
    bgm_files = get_all_bgm_filenames()
    bgm_list_str = json.dumps(bgm_files, ensure_ascii=False)
    
    # ä¿®å¤äº†è¿™é‡Œçš„å­—ç¬¦ä¸²æ‹¼æ¥å’Œæ¢è¡Œé—®é¢˜
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªæœ‰å£°ä¹¦è„šæœ¬åˆ¶ä½œä¸“å®¶ã€‚è¯·å°†è¾“å…¥çš„å°è¯´æ–‡æœ¬æ‹†è§£ä¸º JSON æ•°ç»„ã€‚\n"
        f"å¯ç”¨çš„èƒŒæ™¯éŸ³ä¹/éŸ³æ•ˆåº“å¦‚ä¸‹ï¼š{bgm_list_str}\n\n"
        "ã€æ ¸å¿ƒä»»åŠ¡ã€‘ï¼š\n"
        "å°†å°è¯´åŸæ–‡æ‹†è§£ä¸ºé€‚åˆå¤šäººæœ‰å£°å‰§æœ—è¯»çš„è„šæœ¬ã€‚**åŸæ–‡çš„æ¯ä¸€ä¸ªå­—ã€æ ‡ç‚¹éƒ½å¿…é¡»ä¿ç•™ï¼Œä¸èƒ½æœ‰ä»»ä½•é—æ¼ï¼**\n\n"
        "ã€æ‹†è§£è§„åˆ™ã€‘ï¼š\n"
        "1. **å¯¹è¯å†…å®¹**ï¼ˆå¼•å·å†…ï¼‰ï¼šåˆ†é…ç»™å¯¹åº”çš„è§’è‰²ã€‚\n"
        "2. **éå¯¹è¯å†…å®¹**ï¼ˆå¼•å·å¤–ï¼‰ï¼š**å…¨éƒ¨**åˆ†é…ç»™è§’è‰²â€œæ—ç™½â€ã€‚åŒ…æ‹¬åŠ¨ä½œã€ç¥æ€ã€ä»¥åŠâ€œä»–è¯´â€ã€â€œé“â€ç­‰å¼•å¯¼è¯­ã€‚\n"
        "3. **å¿…é¡»æ‹†åˆ†**ï¼šå½“ä¸€è¡Œæ–‡å­—æ˜¯ [æå†™ + å¯¹è¯] æ—¶ï¼Œå¿…é¡»æ‹†åˆ†ä¸º [æ—ç™½] + [è§’è‰²] ä¸¤æ¡ï¼Œä¸èƒ½åˆå¹¶ï¼\n"
        "4. **æƒ…ç»ªæ§åˆ¶**ï¼šæƒ…ç»ª emotion å¿…é¡»å…‹åˆ¶ï¼ˆå¦‚ç”¨'æ€¥ä¿ƒ'ä»£æ›¿'å’†å“®'ï¼Œç”¨'ä½æ²‰'ä»£æ›¿'æ€’å¼'ï¼‰ã€‚\n\n"
        "5. ã€æ—ç™½ç‰¹æ®Šè§„åˆ™ã€‘ï¼šæ—ç™½æ˜¯â€˜è¯´ä¹¦äººâ€™ï¼Œå¿…é¡»æŠ½ç¦»äºå‰§æƒ…ä¹‹å¤–ã€‚æ— è®ºå‰§æƒ…å¤šä¹ˆæ¿€çƒˆï¼ˆæ‰“æ–—ã€äº‰åµï¼‰ï¼Œæ—ç™½çš„æƒ…ç»ªåªèƒ½æ˜¯ 'æ²‰ç¨³'ã€'è®²è¿°æ„Ÿ'ã€'èˆ’ç¼“' æˆ– 'å¸¦æœ‰æ‚¬å¿µ'ã€‚ä¸¥ç¦ç»™æ—ç™½åˆ†é… 'æ„¤æ€’'ã€'å“­æ³£'ã€'å¤§ç¬‘' ç­‰å…·ä½“çš„äººç‰©æƒ…ç»ªï¼\n\n"
        "ã€æ‹†åˆ†ç¤ºä¾‹ï¼ˆä¸¥æ ¼æ¨¡ä»¿æ­¤é€»è¾‘ï¼‰ã€‘ï¼š\n"
        "è¾“å…¥åŸæ–‡ï¼š\n"
        "çŒªå…«æˆ’ä¸€è§ï¼ŒæŠŠå˜´ä¸€å™˜ï¼Œå˜Ÿå›”é“ï¼šâ€œå¸ˆçˆ¶ï¼Œç³Ÿç³•äº†ï¼â€\n"
        "è¾“å‡º JSONï¼š\n"
        "[\n"
        "  {\"role\": \"æ—ç™½\", \"emotion\": \"æ²‰ç¨³\", \"text\": \"çŒªå…«æˆ’ä¸€è§ï¼ŒæŠŠå˜´ä¸€å™˜ï¼Œå˜Ÿå›”é“ï¼š\", \"bgm\": \"\"},\n"
        "  {\"role\": \"çŒªå…«æˆ’\", \"emotion\": \"å§”å±ˆ\", \"text\": \"å¸ˆçˆ¶ï¼Œç³Ÿç³•äº†ï¼\", \"bgm\": \"funny.mp3\"}\n"
        "]\n\n"
        "è¾“å…¥åŸæ–‡ï¼š\n"
        "â€œå¿«èµ°ï¼â€å­™æ‚Ÿç©ºä¸€æŠŠæ¨å¼€ä»–ï¼Œâ€œåˆ«ç£¨è¹­ï¼â€\n"
        "è¾“å‡º JSONï¼š\n"
        "[\n"
        "  {\"role\": \"å­™æ‚Ÿç©º\", \"emotion\": \"æ€¥ä¿ƒ\", \"text\": \"å¿«èµ°ï¼\", \"bgm\": \"battle.mp3\"},\n"
        "  {\"role\": \"æ—ç™½\", \"emotion\": \"è®²è¿°æ„Ÿ\", \"text\": \"å­™æ‚Ÿç©ºä¸€æŠŠæ¨å¼€ä»–ï¼Œ\", \"bgm\": \"battle.mp3\"},\n"
        "  {\"role\": \"å­™æ‚Ÿç©º\", \"emotion\": \"æ€¥ä¿ƒ\", \"text\": \"åˆ«ç£¨è¹­ï¼\", \"bgm\": \"battle.mp3\"}\n"
        "]\n\n"
        "ç°åœ¨ï¼Œè¯·å¤„ç†ä¸‹é¢çš„æ–‡æœ¬ï¼š"
    )

    try:
        completion = client.chat.completions.create(
            model="qwen-max",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text_content}
            ],
            temperature=0.01 
        )
        return parse_json_output(completion.choices[0].message.content)
    except Exception as e:
        print(f"âŒ LLM é”™è¯¯: {e}")
        return []

# ================= 5. æ ¸å¿ƒæµæ°´çº¿ =================

class VoiceManager:
    def __init__(self, pool_dir):
        self.pool_dir = pool_dir
        self.all_files = []
        if os.path.exists(pool_dir):
            for root, dirs, files in os.walk(pool_dir):
                for file in files:
                    if file.lower().endswith(('.wav', '.mp3')):
                        self.all_files.append(os.path.join(root, file))
        self.selection_cache = {}

    def _ask_llm_to_pick(self, role_name, emotion):
        if not self.all_files: return None
        file_map = {os.path.basename(f): f for f in self.all_files}
        prompt = f"è§’è‰²: {role_name}, æƒ…ç»ª: {emotion}ã€‚è¯·ä»åˆ—è¡¨ {list(file_map.keys())} ä¸­é€‰ä¸€ä¸ªæœ€åˆé€‚çš„æ–‡ä»¶åï¼Œä»…è¾“å‡ºæ–‡ä»¶åï¼Œæ²¡æ‰¾åˆ°è¾“å‡ºNoneã€‚"
        try:
            res = client.chat.completions.create(
                model="qwen-max", messages=[{"role": "user", "content": prompt}], temperature=0.1
            )
            picked = res.choices[0].message.content.strip().replace("'", "").replace('"', "")
            if picked in file_map: return file_map[picked]
        except: pass
        return self.all_files[hash(role_name) % len(self.all_files)]

    def get_smart_voice(self, role_name, emotion=""):
        if role_name in self.selection_cache: return self.selection_cache[role_name]
        selected = self._ask_llm_to_pick(role_name, emotion)
        self.selection_cache[role_name] = selected
        return selected


def process_pipeline_v2(task_id: str, text: str, user_voice_map: dict):
    TASKS[task_id]["status"] = "analyzing"
    
    print("\nğŸ” [1/4] æ­£åœ¨åˆ†ææ–‡æœ¬å¹¶åˆ†é…BGM...")
    dialogues = analyze_novel_roles_llm(text)
    if not dialogues:
        TASKS[task_id]["status"] = "failed"; return

    vm = VoiceManager(VOICE_POOL_DIR)
    
    TASKS[task_id]["status"] = "generating"
    TASKS[task_id]["total"] = len(dialogues)
    
    final_segments = []

    print("\nğŸ—£ï¸ [2/4] å¼€å§‹ç”Ÿæˆè¯­éŸ³å¹¶èåˆèƒŒæ™¯éŸ³...")
    for i, item in enumerate(dialogues):
        TASKS[task_id]["progress"] = int((i / len(dialogues)) * 100)
        role = item["è§’è‰²"]
        line = item["å°è¯"]
        raw_emotion = item.get("æƒ…ç»ª", "")  
        bgm_filename = item.get("bgm", "")

        # å®šä¹‰æƒ…ç»ªé™çº§æ˜ å°„
        safe_emotion_map = {
            "æ„¤æ€’": "å‹æŠ‘çš„æ€’ç«ï¼Œè¯­æ°”å†°å†·", 
            "å’†å“®": "å’¬ç‰™åˆ‡é½¿ï¼Œä½æ²‰",
            "å¤§å–Š": "æ€¥ä¿ƒï¼Œé‡éŸ³",
            "æ­‡æ–¯åº•é‡Œ": "é¢¤æŠ–ï¼Œå“½å’½",
            "å¤§ç¬‘": "è½»ç¬‘",
            "ç‹‚ç¬‘": "å¾—æ„çš„ç¬‘",
            "æ‚²ç—›æ¬²ç»": "æ‚²ä¼¤ï¼Œä½è½",
            "ææƒ§": "ç´§å¼ ï¼Œé¢¤éŸ³",
            "æ¿€æ˜‚": "åšå®šï¼Œæœ‰åŠ›"
        }

        # å¤„ç†æƒ…ç»ª
        if role == "æ—ç™½":
            final_emotion = "æ²‰ç¨³ï¼Œè®²è¿°æ„Ÿï¼Œæ‚¬ç–‘"
        else:
            final_emotion = raw_emotion
            for danger_key, safe_value in safe_emotion_map.items():
                if danger_key in raw_emotion:
                    print(f"   ğŸ›¡ï¸ [éŸ³è‰²ä¿æŠ¤] å°† '{raw_emotion}' é™çº§ä¸º -> '{safe_value}'")
                    final_emotion = safe_value
                    break 

        # æ‰“å°æ—¥å¿—
        bgm_info = f"ğŸµ {bgm_filename}" if bgm_filename else "æ— BGM"
        print(f"\n [{i+1}/{len(dialogues)}] {role}: {line[:15]}... (æƒ…ç»ª: {final_emotion}) | {bgm_info}")

        try:
            # === A. ç¡®å®šéŸ³è‰²é€»è¾‘ ===
            final_wav_path = None
            use_cosy_default = False
            voice_source_type = "æœªçŸ¥"

            # 1. å°è¯•ç”¨æˆ·æŒ‡å®š (ç²¾ç¡®åŒ¹é…)
            if role in user_voice_map: 
                final_wav_path = user_voice_map[role]
                voice_source_type = "ç”¨æˆ·é”å®š"
            
            # 2. å°è¯•ç”¨æˆ·æŒ‡å®š (æ¨¡ç³ŠåŒ¹é…)
            if not final_wav_path:
                for u_role, u_path in user_voice_map.items():
                    if u_role != "æ—ç™½" and role != "æ—ç™½" and (u_role in role or role in u_role):
                        final_wav_path = u_path
                        voice_source_type = f"ç”¨æˆ·æ¨¡ç³Š({u_role})"
                        break
            
            # 3. æ—ç™½é»˜è®¤é€»è¾‘
            if not final_wav_path and role == "æ—ç™½": 
                use_cosy_default = True
                voice_source_type = "ç³»ç»Ÿé»˜è®¤"

            # 4. AI è‡ªåŠ¨é€‰è§’
            if not final_wav_path and not use_cosy_default: 
                # è¿™é‡Œå¿…é¡»ä¼ å…¥ final_emotion è®© AI é€‰è§’æ—¶ä¹ŸçŸ¥é“æƒ…ç»ªå˜äº†ï¼ˆå¯é€‰ï¼‰
                final_wav_path = vm.get_smart_voice(role, final_emotion)
                voice_source_type = "AIè‡ªåŠ¨"

            if use_cosy_default:
                print(f"   ğŸ™ï¸ [éŸ³è‰²] {voice_source_type} -> CosyVoice (ä¸­æ–‡å¥³)")
            elif final_wav_path:
                print(f"   ğŸ™ï¸ [éŸ³è‰²] {voice_source_type} -> æ–‡ä»¶: {os.path.basename(final_wav_path)}")
            else:
                print(f"   âš ï¸ [éŸ³è‰²] æœªæ‰¾åˆ°å¯ç”¨éŸ³è‰²ï¼Œå°†è·³è¿‡ç”Ÿæˆï¼")
                continue

            # === C. å‘é€ç”Ÿæˆè¯·æ±‚ ===
            audio_data = None
            
            if use_cosy_default:
                # CosyVoice é€šå¸¸ä¸éœ€è¦æƒ…ç»ªå‚æ•°ï¼Œæˆ–è€…åªæ¥å—ç‰¹å®šå‚æ•°
                resp = requests.post(URL_COSY, json={"text": line, "speaker": "ä¸­æ–‡å¥³"}, timeout=60)
            else:
                if final_wav_path and os.path.exists(final_wav_path):
                    # ã€é‡è¦ä¿®æ”¹ã€‘è¿™é‡Œå¿…é¡»ä½¿ç”¨å¤„ç†åçš„ final_emotionï¼Œå¦åˆ™éŸ³è‰²ä¿æŠ¤é€»è¾‘ä¸ç”Ÿæ•ˆï¼
                    resp = requests.post(URL_INDEX, json={
                        "text": line, 
                        "emotion": final_emotion,  # <--- ä¿®æ”¹è¿™é‡Œï¼šä½¿ç”¨ final_emotion
                        "ref_audio_path": final_wav_path
                    }, timeout=60)
                else:
                    print(f"   âš ï¸ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸¢å¤±: {final_wav_path}")
                    continue

            if resp and resp.status_code == 200:
                audio_data = resp.content
            else:
                print(f"   âŒ ç”ŸæˆAPIæŠ¥é”™: Code {resp.status_code if resp else 'None'}")
                continue

            # === D. éŸ³é¢‘åå¤„ç† (å½’ä¸€åŒ– & BGM) ===
            import io
            speech_seg = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
            speech_seg = match_target_amplitude(speech_seg, -20.0)
            
            # èåˆ BGM
            bgm_path = os.path.join(BGM_DIR, bgm_filename) if bgm_filename else None
            if bgm_path and os.path.exists(bgm_path):
                mixed_seg = mix_speech_with_bgm(speech_seg, bgm_path)
            else:
                mixed_seg = speech_seg

            final_segments.append(mixed_seg)
            final_segments.append(AudioSegment.silent(duration=300))

        except Exception as e:
            print(f"   âŒ å¤„ç†å¼‚å¸¸: {e}")
            traceback.print_exc()

    # --- 3. æœ€ç»ˆåˆå¹¶ ---
    if not final_segments:
        TASKS[task_id]["status"] = "failed"; return

    print("\nğŸ”¨ [3/4] æ­£åœ¨å¯¼å‡ºæœ€ç»ˆæ–‡ä»¶...")
    full_audio = AudioSegment.empty()
    for seg in final_segments:
        full_audio += seg

    final_name = f"{task_id}.mp3"
    full_audio.export(os.path.join(OUTPUT_DIR, final_name), format="mp3")
    
    TASKS[task_id]["status"] = "completed"
    TASKS[task_id]["result_url"] = f"/download/{final_name}"
    TASKS[task_id]["progress"] = 100
    print(f"\nğŸ‰ [4/4] ä»»åŠ¡å®Œæˆï¼Œæ–‡ä»¶: {final_name}\n")


# ================= 6. API æ¥å£ =================

@app.post("/analyze")
async def analyze_endpoint(file: UploadFile = File(...)):
    content = await file.read()
    text = content.decode("utf-8")
    dialogues = analyze_novel_roles_llm(text)
    unique_roles = set(item['è§’è‰²'] for item in dialogues)
    return {"roles": sorted(list(unique_roles), key=lambda x: 0 if x == "æ—ç™½" else 1)}

@app.post("/generate_step")
async def generate_step(request: Request, bg_tasks: BackgroundTasks):
    form = await request.form()
    file = form.get("file")
    if not file: return JSONResponse(400, {"error": "No file"})
    content = await file.read()
    text = content.decode("utf-8")
    
    user_voice_map = {}
    print("\nğŸ” [DEBUG] æ¥æ”¶å‰ç«¯è¡¨å•æ•°æ®:")
    for k, v in form.items():
        if k == "file": continue
        if k.startswith("custom_voice_") and hasattr(v, "filename") and v.filename:
            role = k.replace("custom_voice_", "")
            safe_name = f"{uuid.uuid4()}_{v.filename}"
            save_path = os.path.join(TEMP_VOICE_DIR, safe_name)
            with open(save_path, "wb") as f: shutil.copyfileobj(v.file, f)
            user_voice_map[role] = os.path.abspath(save_path)
            print(f"   ğŸ“‚ æ”¶åˆ°æ–‡ä»¶: [{role}] -> {v.filename}")
            
        elif k.startswith("preset_voice_") and isinstance(v, str) and v:
            role = k.replace("preset_voice_", "")
            path = os.path.join(VOICE_POOL_DIR, v)
            if os.path.exists(path):
                user_voice_map[role] = os.path.abspath(path)
                print(f"   ğŸµ æ”¶åˆ°é¢„è®¾: [{role}] -> {v}")

    task_id = str(uuid.uuid4())
    TASKS[task_id] = {"status": "pending", "progress": 0}
    bg_tasks.add_task(process_pipeline_v2, task_id, text, user_voice_map)
    return {"task_id": task_id}

@app.get("/status/{task_id}")
def status(task_id: str): return TASKS.get(task_id, {})

@app.get("/download/{name}")
def download(name: str):
    path = os.path.join(OUTPUT_DIR, name)
    return FileResponse(path) if os.path.exists(path) else JSONResponse(404)

@app.get("/", response_class=HTMLResponse)
async def read_root():
    if os.path.exists("index.html"):
        with open("index.html", "r", encoding="utf-8") as f: return f.read()
    return "<h1>index.html Not Found</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)