import os
import sys

# ================= æ ¸å¿ƒé…ç½® (å¿…é¡»æ”¾åœ¨æœ€å¼€å¤´) =================
# 1. ç¦ç”¨ DeepSpeed é›†æˆ (é˜²æ­¢ Triton/CUDA æŠ¥é”™)
os.environ["HfDeepSpeedConfig"] = "5"

# 2. å¼ºåˆ¶ä½¿ç”¨ GPU 0
os.environ["CUDA_VISIBLE_DEVICES"] = "5"
# ========================================================

import torch
import torchaudio
import io
import uvicorn
from fastapi import FastAPI, Response, HTTPException
from pydantic import BaseModel

# === è·¯å¾„é…ç½® ===
# è¯·ç¡®è®¤è¿™ä¸ªè·¯å¾„æ˜¯ä½  CosyVoice é¡¹ç›®çš„çœŸå®è·¯å¾„
COSY_ROOT = "/home/nyw/AI-practice/CosyVoice"
sys.path.append(COSY_ROOT)
sys.path.append(os.path.join(COSY_ROOT, "third_party", "Matcha-TTS"))

# æŒ‡å®šæ¨¡å‹è·¯å¾„ (æ—ç™½æ¨èä½¿ç”¨ SFT æ¨¡å‹)
MODEL_DIR = os.path.join(COSY_ROOT, "pretrained_models/CosyVoice-300M-SFT")

try:
    from cosyvoice.cli.cosyvoice import CosyVoice
except ImportError:
    print("âŒ å¯¼å…¥å¤±è´¥: è¯·æ£€æŸ¥ COSY_ROOT è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
    sys.exit(1)

# === åˆå§‹åŒ–æœåŠ¡ ===
app = FastAPI()

print(f"ğŸš€ [GPU 0] æ­£åœ¨åŠ è½½ CosyVoice æ¨¡å‹: {MODEL_DIR} ...")

if not os.path.exists(MODEL_DIR):
    print(f"âŒ è‡´å‘½é”™è¯¯: æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {MODEL_DIR}")
    print("è¯·å…ˆä» ModelScope ä¸‹è½½ CosyVoice-300M-SFT æ¨¡å‹ã€‚")
    sys.exit(1)

# åŠ è½½æ¨¡å‹ (SFTæ¨¡å¼)
try:
    model = CosyVoice(MODEL_DIR)
    print("âœ… CosyVoice æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

# === å®šä¹‰è¯·æ±‚æ ¼å¼ (å¯¹åº” main_server.py å‘é€çš„ JSON) ===
class NarratorRequest(BaseModel):
    text: str
    speaker: str = "ä¸­æ–‡å¥³"  # é»˜è®¤éŸ³è‰²

@app.post("/generate")
def generate(req: NarratorRequest):
    """
    æ¥æ”¶ JSON: {"text": "...", "speaker": "ä¸­æ–‡å¥³"}
    è¿”å›: WAV éŸ³é¢‘æµ
    """
    try:
        # SFT æ¨ç† (éæµå¼ stream=False)
        output = model.inference_sft(req.text, req.speaker, stream=False)
        
        # æ‹¼æ¥ç”Ÿæˆçš„éŸ³é¢‘ç‰‡æ®µ
        generated_audio_chunks = [item['tts_speech'] for item in output]
        if not generated_audio_chunks:
            raise HTTPException(status_code=500, detail="ç”Ÿæˆç»“æœä¸ºç©º")
            
        final_audio = torch.cat(generated_audio_chunks, dim=1)
        
        # è½¬ä¸º Bytes è¿”å›
        buffer = io.BytesIO()
        # å°† Tensor è½¬å› CPU å¹¶ä¿å­˜ä¸º WAV
        torchaudio.save(buffer, final_audio.cpu(), model.sample_rate, format="wav")
        buffer.seek(0)
        
        return Response(content=buffer.read(), media_type="audio/wav")
        
    except Exception as e:
        print(f"âŒ æ¨ç†å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
def health_check():
    return {"status": "CosyVoice Worker is Running"}

if __name__ == "__main__":
    print("æ­£åœ¨å¯åŠ¨æœåŠ¡ï¼Œç«¯å£: 8005")
    uvicorn.run(app, host="0.0.0.0", port=8005)