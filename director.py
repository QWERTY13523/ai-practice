import os
import json
import uuid
import requests
import re
import shutil
import time
import glob
from fastapi import FastAPI, UploadFile, File, BackgroundTasks, Request, HTTPException
from fastapi.responses import FileResponse, HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydub import AudioSegment
from openai import OpenAI

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# === 1. é…ç½®è·¯å¾„ ===
UPLOAD_DIR = "uploads"
OUTPUT_DIR = "outputs"
TEMP_VOICE_DIR = "uploads/custom_voices"
VOICE_POOL_DIR = "/home/nyw/AI-practice/resource/input_audio"

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(TEMP_VOICE_DIR, exist_ok=True)

# GPU æœåŠ¡åœ°å€
URL_COSY = "http://localhost:8001/generate"
URL_INDEX = "http://localhost:8002/generate"

TASKS = {}

# === 2. åˆå§‹åŒ–å¤§æ¨¡åž‹ ===
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY") or "sk-cfc644272f8b4be2aa58f9b240636083"
client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# === 3. LLM åˆ†æž ===
def parse_json_output(text_output):
    print(f"----- LLM åŽŸå§‹è¿”å›ž (å‰100å­—) -----\n{text_output[:100]}...\n-------------------------------")
    clean_text = re.sub(r'```json\s*', '', text_output)
    clean_text = re.sub(r'```', '', clean_text).strip()
    try:
        data = json.loads(clean_text)
        results = []
        for item in data:
            role = item.get("role", item.get("è§’è‰²", "æ—ç™½")).strip()
            emotion = item.get("emotion", item.get("æƒ…ç»ª", "å¹³æ·¡"))
            text = item.get("text", item.get("å°è¯", ""))
            
            # å¼ºåˆ¶ç»Ÿä¸€æ—ç™½
            if "æ—" in role and "ç™½" in role: role = "æ—ç™½"
            if role.lower() == "narrator": role = "æ—ç™½"
            
            results.append({"è§’è‰²": role, "æƒ…ç»ª": emotion, "å°è¯": text})
        return results
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æžå¤±è´¥: {e}")
        return []

def analyze_novel_roles_llm(text_content):
    try:
        completion = client.chat.completions.create(
            model="qwen-max",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä¸ªå°è¯´æ‹†è§£ä¸“å®¶ã€‚è¯·å°†æ–‡æœ¬æ‹†è§£ä¸º JSON æ•°ç»„ï¼š[{'role': 'XX', 'emotion': 'XX', 'text': '...'}]ã€‚\n"
                        "è§„åˆ™ï¼š1.è§’è‰²åå¿…é¡»ä¿æŒç»Ÿä¸€ã€‚2.æå†™å½’ä¸º'æ—ç™½'ã€‚3.ä¸¥æ ¼JSONæ ¼å¼ã€‚"
                    )
                },
                {"role": "user", "content": text_content}
            ],
            temperature=0.0
        )
        return parse_json_output(completion.choices[0].message.content)
    except Exception as e:
        print(f"âŒ LLM é”™è¯¯: {e}")
        return []

# === 4. éŸ³è‰²ç®¡ç†å™¨ ===
class VoiceManager:
    def __init__(self, pool_dir):
        self.pool_dir = pool_dir
        self.all_files = []
        if os.path.exists(pool_dir):
            for root, dirs, files in os.walk(pool_dir):
                for file in files:
                    if file.lower().endswith(('.wav', '.mp3')):
                        self.all_files.append(os.path.join(root, file))
        self.selection_cache = {}

    def _ask_llm_to_pick(self, role_name, emotion):
        if not self.all_files: return None
        file_map = {os.path.basename(f): f for f in self.all_files}
        prompt = f"è§’è‰²: {role_name}, æƒ…ç»ª: {emotion}ã€‚è¯·ä»Žåˆ—è¡¨ {list(file_map.keys())} ä¸­é€‰ä¸€ä¸ªæœ€åˆé€‚çš„æ–‡ä»¶åï¼Œä»…è¾“å‡ºæ–‡ä»¶åï¼Œæ²¡æ‰¾åˆ°è¾“å‡ºNoneã€‚"
        try:
            print(f"ðŸ¤– [AIé€‰è§’] æ­£åœ¨ä¸º {role_name} æŒ‘é€‰...")
            res = client.chat.completions.create(
                model="qwen-max", messages=[{"role": "user", "content": prompt}], temperature=0.1
            )
            picked = res.choices[0].message.content.strip().replace("'", "").replace('"', "")
            if picked in file_map: return file_map[picked]
        except: pass
        return self.all_files[hash(role_name) % len(self.all_files)]

    def get_smart_voice(self, role_name, emotion=""):
        if role_name in self.selection_cache: return self.selection_cache[role_name]
        selected = self._ask_llm_to_pick(role_name, emotion)
        self.selection_cache[role_name] = selected
        return selected

# === 5. æ ¸å¿ƒæµæ°´çº¿ ===
def process_pipeline_v2(task_id: str, text: str, user_voice_map: dict):
    TASKS[task_id]["status"] = "analyzing"
    
    # ðŸ” å…³é”®è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°åŽç«¯æ”¶åˆ°çš„â€œåœ£æ—¨â€
    print("\n" + "="*40)
    print("ðŸ“‹ [DEBUG] æœ€ç»ˆç”Ÿæ•ˆçš„ç”¨æˆ·é…ç½®è¡¨:")
    if not user_voice_map:
        print("   (ç©º) ç”¨æˆ·æ²¡æœ‰æŒ‡å®šä»»ä½•è§’è‰²ï¼Œå°†å…¨éƒ¨è‡ªåŠ¨åˆ†é…")
    for k, v in user_voice_map.items():
        print(f"   ðŸ”’ è§’è‰²[{k}] ===å¼ºåˆ¶ç»‘å®š===> {os.path.basename(v)}")
    print("="*40 + "\n")

    dialogues = analyze_novel_roles_llm(text)
    if not dialogues:
        TASKS[task_id]["status"] = "failed"; return

    vm = VoiceManager(VOICE_POOL_DIR)
    TASKS[task_id]["status"] = "generating"
    TASKS[task_id]["total"] = len(dialogues)
    audio_segments = []

    for i, item in enumerate(dialogues):
        TASKS[task_id]["progress"] = int((i / len(dialogues)) * 100)
        role = item["è§’è‰²"]
        line = item["å°è¯"]
        emotion = item.get("æƒ…ç»ª", "")
        
        print(f"âž¡ï¸ [{i}] {role}: {line[:10]}...")

        try:
            final_wav_path = None
            use_cosy_default = False

            # === ä¼˜å…ˆçº§ 1: ç”¨æˆ·æŒ‡å®š (æœ€å¼º) ===
            # ç²¾ç¡®åŒ¹é…
            if role in user_voice_map:
                final_wav_path = user_voice_map[role]
                print(f"   âœ¨ [ç”¨æˆ·] ç²¾ç¡®å‘½ä¸­: {role} -> {os.path.basename(final_wav_path)}")
            
            # æ¨¡ç³ŠåŒ¹é… (åŒå‘åŒ…å«)
            if not final_wav_path:
                for u_role, u_path in user_voice_map.items():
                    # æŽ’é™¤æ—ç™½å¹²æ‰°
                    if u_role != "æ—ç™½" and role != "æ—ç™½" and (u_role in role or role in u_role):
                        final_wav_path = u_path
                        print(f"   âœ¨ [ç”¨æˆ·] æ¨¡ç³Šå‘½ä¸­: {role} ~= {u_role}")
                        break
            
            # === ä¼˜å…ˆçº§ 2: æ—ç™½é»˜è®¤ ===
            if not final_wav_path and role == "æ—ç™½":
                use_cosy_default = True
                print("   ðŸŽ™ï¸ [ç³»ç»Ÿ] æ—ç™½èµ°é»˜è®¤ CosyVoice")

            # === ä¼˜å…ˆçº§ 3: AI è‡ªåŠ¨ ===
            if not final_wav_path and not use_cosy_default:
                final_wav_path = vm.get_smart_voice(role, emotion)
                print(f"   ðŸ¤– [AI] è‡ªåŠ¨åˆ†é…: {os.path.basename(final_wav_path)}")

            # === å‘é€è¯·æ±‚ ===
            resp = None
            if use_cosy_default:
                resp = requests.post(URL_COSY, json={"text": line, "speaker": "ä¸­æ–‡å¥³"}, timeout=60)
            else:
                if not final_wav_path or not os.path.exists(final_wav_path):
                    print("   âš ï¸ æ–‡ä»¶ç¼ºå¤±ï¼Œè·³è¿‡")
                    continue
                resp = requests.post(URL_INDEX, json={
                    "text": line, "emotion": emotion, "ref_audio_path": final_wav_path
                }, timeout=60)

            if resp and resp.status_code == 200:
                seg_path = os.path.join(OUTPUT_DIR, f"{task_id}_{i}.wav")
                with open(seg_path, "wb") as f: f.write(resp.content)
                audio_segments.append(seg_path)
            else:
                print(f"   âŒ å¤±è´¥ code={resp.status_code if resp else 'Error'}")

        except Exception as e:
            print(f"   âŒ å¼‚å¸¸: {e}")

    # åˆå¹¶é€»è¾‘
    if not audio_segments:
        TASKS[task_id]["status"] = "failed"; return

    combined = AudioSegment.empty()
    for path in audio_segments:
        try:
            combined += AudioSegment.from_wav(path)
            combined += AudioSegment.silent(duration=500)
            os.remove(path)
        except: pass

    final_name = f"{task_id}.mp3"
    combined.export(os.path.join(OUTPUT_DIR, final_name), format="mp3")
    TASKS[task_id]["status"] = "completed"
    TASKS[task_id]["result_url"] = f"/download/{final_name}"
    TASKS[task_id]["progress"] = 100
    print("ðŸŽ‰ ä»»åŠ¡å®Œæˆ")

# ================= æŽ¥å£ =================

@app.post("/analyze")
async def analyze_endpoint(file: UploadFile = File(...)):
    content = await file.read()
    text = content.decode("utf-8")
    dialogues = analyze_novel_roles_llm(text)
    unique_roles = set(item['è§’è‰²'] for item in dialogues)
    return {"roles": sorted(list(unique_roles), key=lambda x: 0 if x == "æ—ç™½" else 1)}

@app.post("/generate_step")
async def generate_step(request: Request, bg_tasks: BackgroundTasks):
    form = await request.form()
    
    # 1. æå–æ–‡æœ¬
    file = form.get("file")
    if not file: return JSONResponse(400, {"error": "No file"})
    content = await file.read()
    text = content.decode("utf-8")
    
    # 2. æå–ç”¨æˆ·é…ç½® (ä¿®å¤ç‰ˆ)
    user_voice_map = {}
    
    print("\nðŸ” [DEBUG] æŽ¥æ”¶å‰ç«¯è¡¨å•æ•°æ®:")
    for k, v in form.items():
        # å¿½ç•¥ file å­—æ®µï¼Œåªçœ‹ voice é…ç½®
        if k == "file": continue
        
        # === ä¿®å¤ï¼šä¸å†ç”¨ isinstance(v, UploadFile) ===
        # åªè¦å¯¹è±¡æœ‰ filename å±žæ€§ï¼Œæˆ‘ä»¬å°±è®¤ä¸ºå®ƒæ˜¯æ–‡ä»¶
        if k.startswith("custom_voice_") and hasattr(v, "filename") and v.filename:
            role = k.replace("custom_voice_", "")
            safe_name = f"{uuid.uuid4()}_{v.filename}"
            save_path = os.path.join(TEMP_VOICE_DIR, safe_name)
            
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            with open(save_path, "wb") as f:
                shutil.copyfileobj(v.file, f)
                
            user_voice_map[role] = os.path.abspath(save_path)
            print(f"   ðŸ“‚ æ”¶åˆ°æ–‡ä»¶: [{role}] -> {v.filename}")
            
        elif k.startswith("preset_voice_") and isinstance(v, str) and v:
            role = k.replace("preset_voice_", "")
            path = os.path.join(VOICE_POOL_DIR, v)
            if os.path.exists(path):
                user_voice_map[role] = os.path.abspath(path)
                print(f"   ðŸŽµ æ”¶åˆ°é¢„è®¾: [{role}] -> {v}")

    task_id = str(uuid.uuid4())
    TASKS[task_id] = {"status": "pending", "progress": 0}
    bg_tasks.add_task(process_pipeline_v2, task_id, text, user_voice_map)
    return {"task_id": task_id}

@app.get("/status/{task_id}")
def status(task_id: str): return TASKS.get(task_id, {})

@app.get("/download/{name}")
def download(name: str):
    path = os.path.join(OUTPUT_DIR, name)
    return FileResponse(path) if os.path.exists(path) else JSONResponse(404)

@app.get("/", response_class=HTMLResponse)
async def read_root():
    if os.path.exists("index.html"):
        with open("index.html", "r", encoding="utf-8") as f: return f.read()
    return "<h1>index.html Not Found</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)