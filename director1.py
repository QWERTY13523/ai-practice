import os
import json
import uuid
import requests
import re
import shutil
import time
import math
import random
from fastapi import FastAPI, UploadFile, File, BackgroundTasks, Request, HTTPException
from fastapi.responses import FileResponse, HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydub import AudioSegment, effects
from openai import OpenAI

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"],
                   allow_credentials=True)

# === 1. æ ¸å¿ƒè·¯å¾„é…ç½® ===
UPLOAD_DIR = "uploads"
OUTPUT_DIR = "outputs"
TEMP_VOICE_DIR = "uploads/custom_voices"

# èµ„æºåº“è·¯å¾„
VOICE_POOL_DIR = "/home/nyw/AI-practice/resource/pre_train_wav/éŸ³é¢‘/ç¥¥å­/æƒ…ç»ª"
BGM_POOL_DIR = "/home/nyw/AI-practice/resource/pre_train_wav/background"

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(TEMP_VOICE_DIR, exist_ok=True)

# æœåŠ¡åœ°å€
URL_COSY = "http://localhost:8001/generate"
URL_INDEX = "http://localhost:8002/generate"

TASKS = {}

# === 2. åˆå§‹åŒ–å¤§æ¨¡å‹ ===
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY") or "sk-cfc644272f8b4be2aa58f9b240636083"
client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)


# === è¾…åŠ©å·¥å…· ===
def get_file_list(directory, extensions=('.wav', '.mp3')):
    files = []
    if os.path.exists(directory):
        for f in os.listdir(directory):
            if f.lower().endswith(extensions):
                files.append(f)
    return files


# === 3. LLM ç»“æœè§£æ ===
def parse_json_output(text_output):
    print(f"\n{'=' * 20} LLM åŸå§‹è¾“å‡º {'=' * 20}\n{text_output}\n{'=' * 50}\n")

    try:
        start_idx = text_output.find('[')
        end_idx = text_output.rfind(']') + 1

        if start_idx == -1 or end_idx == 0:
            print("âŒ æ— æ³•åœ¨è¾“å‡ºä¸­æ‰¾åˆ° JSON æ•°ç»„ç»“æ„")
            return []

        clean_text = text_output[start_idx:end_idx]
        data = json.loads(clean_text)

        results = []
        valid_emotions = ["æ„¤æ€’", "åŒæ¶", "ææƒ§", "å¹¸ç¦", "æ‚²ä¼¤", "æƒŠå–œ", "æ¿€åŠ¨", "å†…ç–š", "è‡ªè±ª", "é’¦ä½©", "å°´å°¬",]
        valid_timings = ["start", "middle", "end", "loop"]

        for item in data:
            role = item.get("role", "æ—ç™½").strip()
            if role in ["narrator", "Narrator", "", "æ— "]: role = "æ—ç™½"

            emotion = item.get("emotion", "å¹³æ·¡").strip()
            if emotion not in valid_emotions: emotion = "å¹³æ·¡"

            text = item.get("text", "").strip()
            bgm = item.get("bgm", "").strip()
            voice_file = item.get("voice_file", "").strip()

            bgm_timing = item.get("bgm_timing", "start").strip().lower()
            if bgm_timing not in valid_timings: bgm_timing = "start"

            if text:
                results.append({
                    "è§’è‰²": role,
                    "æƒ…ç»ª": emotion,
                    "å°è¯": text,
                    "bgm": bgm,
                    "bgm_timing": bgm_timing,
                    "voice_file": voice_file
                })
        return results
    except Exception as e:
        print(f"âŒ JSON è§£æå¼‚å¸¸: {e}")
        return []


# === 4. Prompt è®¾è®¡ ===
def analyze_novel_roles_llm(text_content):
    bgm_files = get_file_list(BGM_POOL_DIR)
    voice_files = get_file_list(VOICE_POOL_DIR)

    bgm_prompt_list = ", ".join([f"'{f}'" for f in bgm_files]) if bgm_files else "æ— "
    voice_prompt_list = ", ".join([f"'{f}'" for f in voice_files]) if voice_files else "æ— "

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªæå…¶ç»†è‡´çš„æœ‰å£°ä¹¦å¯¼æ¼”ã€‚è¯·å°†å°è¯´æ‹†è§£ä¸º JSON æ•°ç»„ã€‚\n"
        "æ¯ä¸ªå…ƒç´ åŒ…å«ï¼š{'role': '...', 'emotion': '...', 'text': '...', 'bgm': '...', 'bgm_timing': '...', 'voice_file': '...'}\n\n"
        "ã€å…³é”®è§„åˆ™ã€‘ï¼š\n"
        "1. **ç»ä¸é—æ¼æ—ç™½**ï¼š\n"
        "   - ä»»ä½•æœªåŒ…å«åœ¨å¼•å·ï¼ˆâ€œâ€ï¼‰å†…çš„æ–‡å­—ï¼Œå¿…é¡»å•ç‹¬æ‹†åˆ†ä¸ºä¸€æ¡ï¼Œè§’è‰²ä¸º 'æ—ç™½'ã€‚\n"
        "2. **èƒŒæ™¯éŸ³(bgm)ä¸æ—¶æœº(bgm_timing)**ï¼š\n"
        "   - **bgm**: ä»åˆ—è¡¨ä¸­é€‰æ‹©æœ€åŒ¹é…çš„è‹±æ–‡æ–‡ä»¶åï¼ˆå¦‚ 'drop_chopsticks.mp3'ï¼‰ï¼Œæ— åŒ¹é…å¡« \"\"ã€‚\n"
        "     å¯ç”¨åˆ—è¡¨ï¼š[{bgm_prompt_list}]\n"
        "   - **bgm_timing**: ['start', 'middle', 'end', 'loop']ã€‚\n"
        "3. **æƒ…ç»ª**ï¼š[æ„¤æ€’, åŒæ¶, ææƒ§, å¹¸ç¦, æ‚²ä¼¤, æƒŠå–œ, æ¿€åŠ¨, å†…ç–š, è‡ªè±ª, é’¦ä½©, å°´å°¬, å¹³æ·¡]\n"
        "4. **éŸ³è‰²æ–‡ä»¶(voice_file)**ï¼š\n"
        "   - ä»åˆ—è¡¨ä¸­ä¸ºè§’è‰²é€‰ä¸€ä¸ªæœ€åˆé€‚çš„æ–‡ä»¶ï¼ˆä¾‹å¦‚ç»™è€çˆ·çˆ·é€‰è‹è€ç”·å£°ï¼‰ã€‚\n"
        f"   - å¯ç”¨åˆ—è¡¨ï¼š[{voice_prompt_list}]\n"
        "5. **è¾“å‡º**ï¼šåªè¾“å‡º JSON æ•°ç»„ï¼Œæ— å…¶ä»–åºŸè¯ã€‚\n"
    )

    try:
        completion = client.chat.completions.create(
            model="qwen-max",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text_content}
            ],
            temperature=0.1
        )
        return parse_json_output(completion.choices[0].message.content)
    except Exception as e:
        print(f"âŒ API è°ƒç”¨é”™è¯¯: {e}")
        return []


# === 5. å¤„ç†æµæ°´çº¿ ===
def process_pipeline_v2(task_id: str, text: str, user_voice_map: dict):
    TASKS[task_id]["status"] = "analyzing"
    TASKS[task_id]["message"] = "AI æ­£åœ¨ç»†è‡´æ‹†è§£å‰§æœ¬..."

    # 1. é¢„åŠ è½½èƒŒæ™¯éŸ³ (éŸ³é‡å¢å¼ºç‰ˆ)
    bgm_cache = {}
    if os.path.exists(BGM_POOL_DIR):
        for f in os.listdir(BGM_POOL_DIR):
            if f.lower().endswith(('.wav', '.mp3')):
                full_path = os.path.join(BGM_POOL_DIR, f)
                try:
                    # åŸºç¡€æ ‡å‡†åŒ– + 5dB å¢ç›Š
                    sound = AudioSegment.from_file(full_path)
                    bgm_cache[f] = effects.normalize(sound) + 5
                except:
                    pass

    # 2. åˆ†æ
    dialogues = analyze_novel_roles_llm(text)
    if not dialogues:
        TASKS[task_id]["status"] = "failed"
        TASKS[task_id]["message"] = "åˆ†æå¤±è´¥"
        return

    TASKS[task_id]["status"] = "generating"
    TASKS[task_id]["total"] = len(dialogues)

    segments_data = []
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {len(dialogues)} ä¸ªç‰‡æ®µ...")

    # è·å–æ‰€æœ‰å¯ç”¨éŸ³è‰²ç”¨äºå…œåº•
    all_available_voices = get_file_list(VOICE_POOL_DIR)

    # 3. ç”Ÿæˆ
    for i, item in enumerate(dialogues):
        progress = int((i / len(dialogues)) * 100)
        TASKS[task_id]["progress"] = progress
        TASKS[task_id]["message"] = f"æ­£åœ¨å½•åˆ¶: {item['è§’è‰²']} ({i + 1}/{len(dialogues)})"

        role = item["è§’è‰²"]
        line = item["å°è¯"]
        emotion = item.get("æƒ…ç»ª", "å¹³æ·¡")
        bgm_name = item.get("bgm", "")
        bgm_timing = item.get("bgm_timing", "start")
        llm_voice = item.get("voice_file", "")

        print(f"\nğŸ”µ [å¥å­ {i + 1}] {role}: {line[:15]}...")
        print(f"   â””â”€ ğŸ§  é…ç½®: æƒ…ç»ª[{emotion}] | BGM[{bgm_name} @ {bgm_timing}]")

        try:
            # === éŸ³è‰²é€‰æ‹©é€»è¾‘ (ä¸¥æ ¼éµå¾ªï¼šç”¨æˆ· -> LLM -> å…œåº•) ===
            ref_wav_path = None
            source_type = "æœªçŸ¥"

            # ä¼˜å…ˆçº§ 1: ç”¨æˆ·æŒ‡å®š (æœ€é«˜)
            # user_voice_map åŒ…å«äº†ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„æˆ–é€‰æ‹©çš„é¢„è®¾æ–‡ä»¶è·¯å¾„
            if role in user_voice_map:
                ref_wav_path = user_voice_map[role]
                if "custom_voices" in ref_wav_path:
                    source_type = "â­ ç”¨æˆ·ä¸Šä¼ "
                else:
                    source_type = "ğŸ¹ ç”¨æˆ·é¢„è®¾"

            # ä¼˜å…ˆçº§ 2: LLM åŒ¹é… (ç”¨æˆ·æœªæŒ‡å®šæ—¶ä½¿ç”¨)
            # å¿…é¡»æ£€æŸ¥ LLM æ¨èçš„æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨äºåº“ä¸­
            if not ref_wav_path and llm_voice:
                potential_path = os.path.join(VOICE_POOL_DIR, llm_voice)
                if os.path.exists(potential_path):
                    ref_wav_path = potential_path
                    source_type = "ğŸ¤– LLMæ¨è"

            # ä¼˜å…ˆçº§ 3: éšæœºå…œåº• (å‰ä¸¤è€…éƒ½æ— æ•ˆæ—¶ä½¿ç”¨)
            if not ref_wav_path and all_available_voices:
                seed = sum(ord(c) for c in role)
                selected = all_available_voices[seed % len(all_available_voices)]
                ref_wav_path = os.path.join(VOICE_POOL_DIR, selected)
                source_type = "ğŸ² ç³»ç»Ÿå…œåº•"

            # å¼‚å¸¸æ£€æŸ¥
            if not ref_wav_path or not os.path.exists(ref_wav_path):
                print(f"   âŒ [é”™è¯¯] æ‰¾ä¸åˆ°å‚è€ƒéŸ³é¢‘ (è§’è‰²:{role})ï¼Œè·³è¿‡æ­¤å¥ï¼")
                continue

            # æ—¥å¿—ç¡®è®¤
            print(f"   â””â”€ ğŸ’¿ [é€‰å®š] {source_type}: {os.path.basename(ref_wav_path)}")

            # å‘é€è¯·æ±‚
            resp = None
            if role == "æ—ç™½":
                with open(ref_wav_path, "rb") as f:
                    files = {"prompt_wav": ("ref.wav", f, "audio/wav")}
                    data = {"text": line}
                    resp = requests.post(URL_COSY, data=data, files=files, timeout=60)
            else:
                payload = {"text": line, "emotion": emotion, "ref_audio_path": ref_wav_path}
                resp = requests.post(URL_INDEX, json=payload, timeout=60)

            if resp and resp.status_code == 200:
                seg_path = os.path.join(OUTPUT_DIR, f"{task_id}_{i}.wav")
                with open(seg_path, "wb") as f:
                    f.write(resp.content)
                segments_data.append({"path": seg_path, "bgm": bgm_name, "timing": bgm_timing})
                print(f"   â””â”€ âœ… ç”ŸæˆæˆåŠŸ")
            else:
                print(f"   â””â”€ âŒ ç”Ÿæˆå¤±è´¥: {resp.status_code if resp else 'No Response'}")

        except Exception as e:
            print(f"   â””â”€ âŒ å¼‚å¸¸: {e}")

    # 4. åˆæˆ (éŸ³é‡ä¼˜åŒ–ç‰ˆ)
    if not segments_data:
        TASKS[task_id]["status"] = "failed";
        return

    TASKS[task_id]["message"] = "æ­£åœ¨æ™ºèƒ½æ··éŸ³..."
    full_audio = AudioSegment.empty()

    for seg in segments_data:
        p = seg["path"]
        b = seg["bgm"]
        timing = seg["timing"]

        try:
            voice = AudioSegment.from_wav(p)
            voice = effects.normalize(voice)  # äººå£°æ ‡å‡†åŒ–

            if b and b in bgm_cache:
                bgm = bgm_cache[b]  # å·²+5dB
                if len(bgm) > 0:
                    # åœºæ™¯ A: ç¯å¢ƒå¾ªç¯ (Loop)
                    if timing == "loop":
                        # ä¹‹å‰æ˜¯ -12dBï¼Œç°åœ¨æ”¹ä¸º -8dBï¼Œè®©ç¯å¢ƒéŸ³æ›´æ˜æ˜¾ä¸€ç‚¹
                        bgm_loop = bgm - 8
                        loops = math.ceil(len(voice) / len(bgm_loop))
                        bgm_looped = (bgm_loop * loops)[:len(voice)]
                        voice = voice.overlay(bgm_looped)
                        print(f"   ğŸŒ§ï¸ [Loop] æ··å…¥ç¯å¢ƒ: {b}")

                    # åœºæ™¯ B: çŸ­éŸ³æ•ˆ (SFX)
                    else:
                        # ä¹‹å‰æ˜¯ -2dBï¼Œç°åœ¨æ”¹ä¸º +0dB (åŸå£°å åŠ )ï¼Œç¡®ä¿å“äº®
                        bgm_sfx = bgm
                        pos = 0
                        if timing == "start":
                            pos = 0
                        elif timing == "middle":
                            pos = max(0, len(voice) // 2 - len(bgm_sfx) // 2)
                        elif timing == "end":
                            pos = max(0, len(voice) - len(bgm_sfx))

                        voice = voice.overlay(bgm_sfx, position=pos)
                        print(f"   ğŸ’¥ [{timing.upper()}] æ’å…¥éŸ³æ•ˆ: {b}")

            full_audio += voice
            full_audio += AudioSegment.silent(duration=400)
            os.remove(p)
        except Exception as e:
            if os.path.exists(p): os.remove(p)

    final_name = f"{task_id}.mp3"
    full_audio.export(os.path.join(OUTPUT_DIR, final_name), format="mp3")

    TASKS[task_id]["status"] = "completed"
    TASKS[task_id]["result_url"] = f"/download/{final_name}"
    TASKS[task_id]["progress"] = 100
    print(f"\nâœ… å…¨éƒ¨å®Œæˆ: {final_name}")


# ================= API =================

@app.post("/analyze")
async def analyze_endpoint(file: UploadFile = File(...)):
    content = await file.read()
    text = content.decode("utf-8")
    results = analyze_novel_roles_llm(text[:1500])
    roles = set(r['è§’è‰²'] for r in results)
    return {"roles": sorted(list(roles), key=lambda x: 0 if x == "æ—ç™½" else 1)}


@app.post("/generate_step")
async def generate_step(request: Request, bg_tasks: BackgroundTasks):
    form = await request.form()
    file = form.get("file")
    if not file: return JSONResponse(400, {"message": "No file"})
    content = await file.read()
    text = content.decode("utf-8")

    user_voice_map = {}

    # åˆ†ç±»å¤„ç†è¡¨å•é¡¹
    custom_files = []
    preset_choices = []

    for k, v in form.items():
        if k.startswith("custom_voice_"):
            custom_files.append((k, v))
        elif k.startswith("preset_voice_"):
            preset_choices.append((k, v))

    # 1. ä¼˜å…ˆå¤„ç†ä¸Šä¼  (æœ€é«˜ä¼˜å…ˆçº§)
    for k, v in custom_files:
        if hasattr(v, "filename") and v.filename:
            role = k.replace("custom_voice_", "")
            ext = os.path.splitext(v.filename)[1] or ".wav"
            save_name = f"{uuid.uuid4()}{ext}"
            save_path = os.path.join(TEMP_VOICE_DIR, save_name)
            try:
                await v.seek(0)
                with open(save_path, "wb") as f:
                    shutil.copyfileobj(v.file, f)
                user_voice_map[role] = os.path.abspath(save_path)
                print(f"ğŸ“¥ [é…ç½®] è§’è‰² [{role}] -> é‡‡ç”¨ä¸Šä¼ æ–‡ä»¶: {save_path}")
            except Exception as e:
                print(f"âŒ [é…ç½®] ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

    # 2. å¤„ç†é¢„è®¾ (ä»…å½“æ— ä¸Šä¼ æ—¶ç”Ÿæ•ˆ)
    for k, v in preset_choices:
        if isinstance(v, str) and v:
            role = k.replace("preset_voice_", "")
            if role not in user_voice_map:
                full_path = os.path.join(VOICE_POOL_DIR, v)
                if os.path.exists(full_path):
                    user_voice_map[role] = full_path
                    print(f"ğŸ‘‰ [é…ç½®] è§’è‰² [{role}] -> é‡‡ç”¨é¢„è®¾: {v}")

    task_id = str(uuid.uuid4())
    TASKS[task_id] = {"status": "analyzing", "progress": 0, "message": "å·²æäº¤..."}
    bg_tasks.add_task(process_pipeline_v2, task_id, text, user_voice_map)
    return {"task_id": task_id}


@app.get("/status/{task_id}")
def status(task_id: str): return TASKS.get(task_id, {})


@app.get("/download/{name}")
def download(name: str):
    path = os.path.join(OUTPUT_DIR, name)
    return FileResponse(path) if os.path.exists(path) else JSONResponse(404)


@app.get("/", response_class=HTMLResponse)
async def read_root():
    if os.path.exists("index1.html"):
        with open("index1.html", "r", encoding="utf-8") as f: return f.read()
    if os.path.exists("index.html"):
        with open("index.html", "r", encoding="utf-8") as f: return f.read()
    return "<h1>Running</h1>"


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=9000)